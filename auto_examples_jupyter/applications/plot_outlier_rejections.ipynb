{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Customized sampler to implement an outlier rejections estimator\n\nThis example illustrates the use of a custom sampler to implement an outlier\nrejections estimator. It can be used easily within a pipeline in which the\nnumber of samples can vary during training, which usually is a limitation of\nthe current scikit-learn pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Guillaume Lemaitre <g.lemaitre58@gmail.com>\n# License: MIT\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_moons, make_blobs\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\nfrom imblearn import FunctionSampler\nfrom imblearn.pipeline import make_pipeline\n\nprint(__doc__)\n\nrng = np.random.RandomState(42)\n\n\ndef plot_scatter(X, y, title):\n    \"\"\"Function to plot some data as a scatter plot.\"\"\"\n    plt.figure()\n    plt.scatter(X[y == 1, 0], X[y == 1, 1], label=\"Class #1\")\n    plt.scatter(X[y == 0, 0], X[y == 0, 1], label=\"Class #0\")\n    plt.legend()\n    plt.title(title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Toy data generation\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are generating some non Gaussian data set contaminated with some unform\nnoise.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "moons, _ = make_moons(n_samples=500, noise=0.05)\nblobs, _ = make_blobs(\n    n_samples=500, centers=[(-0.75, 2.25), (1.0, 2.0)], cluster_std=0.25\n)\noutliers = rng.uniform(low=-3, high=3, size=(500, 2))\nX_train = np.vstack([moons, blobs, outliers])\ny_train = np.hstack(\n    [\n        np.ones(moons.shape[0], dtype=np.int8),\n        np.zeros(blobs.shape[0], dtype=np.int8),\n        rng.randint(0, 2, size=outliers.shape[0], dtype=np.int8),\n    ]\n)\n\nplot_scatter(X_train, y_train, \"Training dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will generate some cleaned test data without outliers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "moons, _ = make_moons(n_samples=50, noise=0.05)\nblobs, _ = make_blobs(\n    n_samples=50, centers=[(-0.75, 2.25), (1.0, 2.0)], cluster_std=0.25\n)\nX_test = np.vstack([moons, blobs])\ny_test = np.hstack(\n    [np.ones(moons.shape[0], dtype=np.int8), np.zeros(blobs.shape[0], dtype=np.int8)]\n)\n\nplot_scatter(X_test, y_test, \"Testing dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to use the :class:`~imblearn.FunctionSampler`\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first define a function which will use\n:class:`~sklearn.ensemble.IsolationForest` to eliminate some outliers from\nour dataset during training. The function passed to the\n:class:`~imblearn.FunctionSampler` will be called when using the method\n``fit_resample``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def outlier_rejection(X, y):\n    \"\"\"This will be our function used to resample our dataset.\"\"\"\n    model = IsolationForest(max_samples=100, contamination=0.4, random_state=rng)\n    model.fit(X)\n    y_pred = model.predict(X)\n    return X[y_pred == 1], y[y_pred == 1]\n\n\nreject_sampler = FunctionSampler(func=outlier_rejection)\nX_inliers, y_inliers = reject_sampler.fit_resample(X_train, y_train)\nplot_scatter(X_inliers, y_inliers, \"Training data without outliers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Integrate it within a pipeline\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By elimnating outliers before the training, the classifier will be less\naffected during the prediction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipe = make_pipeline(\n    FunctionSampler(func=outlier_rejection),\n    LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\", random_state=rng),\n)\ny_pred = pipe.fit(X_train, y_train).predict(X_test)\nprint(classification_report(y_test, y_pred))\n\nclf = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\", random_state=rng)\ny_pred = clf.fit(X_train, y_train).predict(X_test)\nprint(classification_report(y_test, y_pred))\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}